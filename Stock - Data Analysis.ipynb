{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n",
    "\n",
    "This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "523d4727-def8-4767-b155-67ec59c9b2a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Import Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03ec5e54-9b1f-45b1-8f54-382e4cce6d12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to load and process stock data\n",
    "def load_and_process_data(file_location, infer_schema=\"false\", first_row_is_header=\"false\", delimiter=\",\"):\n",
    "    \"\"\"\n",
    "    Loads a CSV file, processes its header, removes the first row, and renames the first column to 'Date'.\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = spark.read.format(\"csv\") \\\n",
    "        .option(\"inferSchema\", infer_schema) \\\n",
    "        .option(\"header\", first_row_is_header) \\\n",
    "        .option(\"sep\", delimiter) \\\n",
    "        .load(file_location)\n",
    "\n",
    "    # Add an index to each row\n",
    "    df_with_index = df.rdd.zipWithIndex().toDF()\n",
    "\n",
    "    # Rename columns: first column contains data, second column contains index\n",
    "    df_with_index = df_with_index.select(\"_1\", \"_2\")\n",
    "\n",
    "    # Filter out the first and third rows based on their index\n",
    "    df_filtered = df_with_index.filter(~(df_with_index[\"_2\"] == 0) & ~(df_with_index[\"_2\"] == 2))\n",
    "\n",
    "    # Extract the first row to use as column names\n",
    "    new_columns = df_filtered.first()[0]\n",
    "\n",
    "    # Convert DataFrame to use proper column names from extracted row\n",
    "    df = df_filtered.select(\"_1.*\").toDF(*new_columns)\n",
    "\n",
    "    # Remove the first row from the DataFrame\n",
    "    first_row = df.limit(1)\n",
    "    df = df.subtract(first_row)\n",
    "\n",
    "    # Rename the first column dynamically to \"Date\"\n",
    "    first_col_name = df.columns[0]\n",
    "    df = df.withColumnRenamed(first_col_name, \"Date\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load and process each dataset\n",
    "df_volume = load_and_process_data(\"/FileStore/tables/Volume.csv\", infer_schema=\"true\")\n",
    "df_open = load_and_process_data(\"/FileStore/tables/Open.csv\", infer_schema=\"true\")\n",
    "df_close = load_and_process_data(\"/FileStore/tables/Close.csv\", infer_schema=\"true\")\n",
    "df_high = load_and_process_data(\"/FileStore/tables/High.csv\", infer_schema=\"true\")\n",
    "df_low = load_and_process_data(\"/FileStore/tables/Low.csv\", infer_schema=\"true\")\n",
    "\n",
    "# Display processed DataFrames\n",
    "display(df_volume.orderBy(\"Date\").limit(10))\n",
    "display(df_open.orderBy(\"Date\").limit(10))\n",
    "display(df_close.orderBy(\"Date\").limit(10))\n",
    "display(df_high.orderBy(\"Date\").limit(10))\n",
    "display(df_low.orderBy(\"Date\").limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13492eb2-639e-4003-abed-a7dd83adf684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create temp view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd82bb99-1479-4d5c-be10-8c36df0f1d44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a view or table\n",
    "temp_table_volume = \"Volume_csv\"\n",
    "temp_table_low = \"Low_csv\"\n",
    "temp_table_high = \"High_csv\"\n",
    "temp_table_open = \"Open_csv\"\n",
    "temp_table_close = \"Close_csv\"\n",
    "\n",
    "df_volume.createOrReplaceTempView(temp_table_volume)\n",
    "df_low.createOrReplaceTempView(temp_table_low)\n",
    "df_high.createOrReplaceTempView(temp_table_high)\n",
    "df_open.createOrReplaceTempView(temp_table_open)\n",
    "df_close.createOrReplaceTempView(temp_table_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15f57771-3a1e-4cad-9a51-2c97b50346bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Basic SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5f66379-6f7f-42ec-8e82-d0e0926a1721",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1: Get the latest closing price for all stocks\n",
    "SELECT * \n",
    "FROM Close_csv\n",
    "WHERE date = (SELECT MAX(date) FROM Close_csv);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03468e9a-1478-437a-a83b-7dd96bedbc5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 2: Find the total trading volume for each stock over all time\n",
    "SELECT \n",
    "    SUM(AAPL) AS AAPL_total_volume, \n",
    "    SUM(MSFT) AS MSFT_total_volume, \n",
    "    SUM(GOOGL) AS GOOGL_total_volume\n",
    "FROM Volume_csv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbc1077e-5fa5-44da-afbb-8acd342fe32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 3: Get the lowest opening price for all stocks\n",
    "SELECT \n",
    "    MIN(AAPL) AS AAPL_min_open, \n",
    "    MIN(MSFT) AS MSFT_min_open, \n",
    "    MIN(GOOGL) AS GOOGL_min_open\n",
    "FROM Open_csv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5964c81a-6003-4db5-9d80-12bc6c03d90a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 4: Get the highest closing price for all stocks\n",
    "SELECT \n",
    "    MAX(AAPL) AS AAPL_max_close, \n",
    "    MAX(MSFT) AS MSFT_max_close, \n",
    "    MAX(GOOGL) AS GOOGL_max_close\n",
    "FROM Close_csv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01e47043-48e0-462e-bf88-787d9dac1952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 5: Find the average closing price for each stock in the last month\n",
    "SELECT \n",
    "    AVG(AAPL) AS AAPL_avg_close, \n",
    "    AVG(MSFT) AS MSFT_avg_close, \n",
    "    AVG(GOOGL) AS GOOGL_avg_close\n",
    "FROM Close_csv\n",
    "WHERE date >= DATE_SUB(CURRENT_DATE(), 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de6b8397-0e17-4096-ab78-afa9334e1675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 6: Simple Query to Compare Close and Open Prices\n",
    "SELECT c.date, \n",
    "       c.AAPL, \n",
    "       o.AAPL AS Open_AAPL\n",
    "FROM Close_csv c\n",
    "JOIN Open_csv o ON c.date = o.date\n",
    "WHERE c.AAPL > o.AAPL\n",
    "ORDER BY c.date DESC\n",
    "LIMIT 10;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddbd7a47-2559-4d32-bbab-6e081093c3b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 7: Find the number of trading days in the dataset\n",
    "SELECT COUNT(DISTINCT date) AS trading_days FROM Close_csv;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e9666e-9f65-4af9-b5d2-13171b94397a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 8: Retrieve stock prices for a specific date range\n",
    "SELECT * FROM Close_csv WHERE date BETWEEN '2024-01-01' AND '2024-02-01';\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47c469cc-3632-48fb-9d58-559184c6ee2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 9: Find the first recorded closing price for each stock\n",
    "SELECT * FROM Close_csv WHERE date = (SELECT MIN(date) FROM Close_csv);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4df9e5da-2f70-4040-be66-e53a79fd001f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 10: Find stocks with the highest trading volume on any single day\n",
    "SELECT date, \n",
    "       MAX(AAPL) AS max_AAPL_volume, \n",
    "       MAX(MSFT) AS max_MSFT_volume, \n",
    "       MAX(GOOGL) AS max_GOOGL_volume\n",
    "FROM Volume_csv\n",
    "GROUP BY date\n",
    "ORDER BY date DESC;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6da46241-8780-446a-ba92-3977d7c57095",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Medium SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72079330-2119-4de5-a38b-480124170e19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 11: Find the Average Closing Price for Each Stock Over the Last 30 Days\n",
    "SELECT 'AAPL' AS stock, AVG(CAST(AAPL AS DOUBLE)) AS avg_close\n",
    "FROM Close_csv\n",
    "WHERE date >= DATEADD(DAY, -30, CURRENT_DATE)\n",
    "UNION\n",
    "SELECT 'MSFT' AS stock, AVG(CAST(MSFT AS DOUBLE)) AS avg_close\n",
    "FROM Close_csv\n",
    "WHERE date >= DATEADD(DAY, -30, CURRENT_DATE)\n",
    "UNION\n",
    "SELECT 'GOOGL' AS stock, AVG(CAST(GOOGL AS DOUBLE)) AS avg_close\n",
    "FROM Close_csv\n",
    "WHERE date >= DATEADD(DAY, -30, CURRENT_DATE);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e94ed135-a916-4092-8791-997851a3adca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 12: Find Days Where AAPL Closed Above Its 30-Day Average\n",
    "SELECT date, AAPL\n",
    "FROM Close_csv\n",
    "WHERE CAST(AAPL AS DOUBLE) > (\n",
    "    SELECT AVG(CAST(AAPL AS DOUBLE)) \n",
    "    FROM Close_csv\n",
    "    WHERE date >= DATEADD(DAY, -30, CURRENT_DATE)\n",
    ")\n",
    "ORDER BY date DESC;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc806a64-6b9c-4dbb-a8a5-84e574a2ca1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 13: Find the Highest Opening Price for Each Stock in the Last 60 Days\n",
    "SELECT 'AAPL' AS stock, MAX(CAST(AAPL AS DOUBLE)) AS max_open\n",
    "FROM Open_csv\n",
    "WHERE date >= DATEADD(DAY, -60, CURRENT_DATE)\n",
    "UNION\n",
    "SELECT 'MSFT' AS stock, MAX(CAST(MSFT AS DOUBLE)) AS max_open\n",
    "FROM Open_csv\n",
    "WHERE date >= DATEADD(DAY, -60, CURRENT_DATE)\n",
    "UNION\n",
    "SELECT 'GOOGL' AS stock, MAX(CAST(GOOGL AS DOUBLE)) AS max_open\n",
    "FROM Open_csv\n",
    "WHERE date >= DATEADD(DAY, -60, CURRENT_DATE);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93b06aab-d48d-48e2-81a7-33468af181d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 14: Find Stocks Where the Closing Price Increased for 3 Consecutive Days\n",
    "SELECT c1.date, c1.AAPL\n",
    "FROM Close_csv c1\n",
    "JOIN Close_csv c2 ON c1.date = DATEADD(DAY, -1, c2.date)\n",
    "JOIN Close_csv c3 ON c2.date = DATEADD(DAY, -1, c3.date)\n",
    "WHERE CAST(c1.AAPL AS DOUBLE) > CAST(c2.AAPL AS DOUBLE)\n",
    "  AND CAST(c2.AAPL AS DOUBLE) > CAST(c3.AAPL AS DOUBLE)\n",
    "ORDER BY c1.date DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e84c7f1-0285-4a9a-bfc4-a5fe58aec383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 15: Find Days Where AAPL Had the Highest Trading Volume Among AAPL, MSFT, and GOOGL\n",
    "SELECT v.date\n",
    "FROM Volume_csv v\n",
    "WHERE CAST(v.AAPL AS DOUBLE) > CAST(v.MSFT AS DOUBLE)\n",
    "  AND CAST(v.AAPL AS DOUBLE) > CAST(v.GOOGL AS DOUBLE);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0b33710-18c3-4be3-9485-177f413a8f02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 16: Find the Dates When AAPL and MSFT Both Closed Higher Than They Opened\n",
    "SELECT c.date, c.AAPL, c.MSFT\n",
    "FROM Close_csv c\n",
    "JOIN Open_csv o ON c.date = o.date\n",
    "WHERE CAST(c.AAPL AS DOUBLE) > CAST(o.AAPL AS DOUBLE)\n",
    "  AND CAST(c.MSFT AS DOUBLE) > CAST(o.MSFT AS DOUBLE)\n",
    "ORDER BY c.date DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4d53fb5-8b9f-43cd-97e1-ba57819a336e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 17: Find the Highest and Lowest Closing Price of AAPL in the Last 3 Months\n",
    "SELECT \n",
    "    MAX(CAST(AAPL AS DOUBLE)) AS highest_close,\n",
    "    MIN(CAST(AAPL AS DOUBLE)) AS lowest_close\n",
    "FROM Close_csv\n",
    "WHERE date >= DATEADD(MONTH, -3, CURRENT_DATE);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecb21935-caff-44c9-b3e6-903118457f65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 18: Find Stocks Where the Daily Fluctuation Was Greater Than 5%\n",
    "SELECT h.date, \n",
    "       h.AAPL, l.AAPL,\n",
    "       ((CAST(h.AAPL AS DOUBLE) - CAST(l.AAPL AS DOUBLE)) / CAST(l.AAPL AS DOUBLE)) * 100 AS fluctuation_percent\n",
    "FROM High_csv h\n",
    "JOIN Low_csv l ON h.date = l.date\n",
    "WHERE ((CAST(h.AAPL AS DOUBLE) - CAST(l.AAPL AS DOUBLE)) / CAST(l.AAPL AS DOUBLE)) * 100 > 5\n",
    "ORDER BY fluctuation_percent DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e86942f8-7062-4355-b932-09131a970828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 19: Find Stocks Where the Name Ends With 'L'\n",
    "df_close = spark.table(\"Close_csv\")\n",
    "\n",
    "# Get the list of column names\n",
    "columns = df_close.columns\n",
    "\n",
    "# Filter column names that end with 'L'\n",
    "columns_ending_with_L = [col for col in columns if col.endswith('L')]\n",
    "\n",
    "# Print the result\n",
    "print(columns_ending_with_L)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25f718ce-5610-445e-8ecc-dfc731320c1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 20: Find Days Where AAPL's Trading Volume Was Above Its 50-Day Average\n",
    "SELECT v.date, v.AAPL\n",
    "FROM Volume_csv v\n",
    "WHERE CAST(v.AAPL AS DOUBLE) > (\n",
    "    SELECT AVG(CAST(AAPL AS DOUBLE)) \n",
    "    FROM Volume_csv\n",
    "    WHERE date >= DATEADD(DAY, -50, CURRENT_DATE)\n",
    ")\n",
    "ORDER BY v.date DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d6868c2-fb53-4010-9860-0b0a1ab4fe29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Advanced SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d731fd99-4a6d-45b5-84ae-2510e3d6b589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 21: Common Table Expression (CTE) to Find AAPL’s Price Difference\n",
    "WITH AAPL_Changes AS (\n",
    "    SELECT date, \n",
    "           CAST(AAPL AS DOUBLE) AS close_price,\n",
    "           LAG(CAST(AAPL AS DOUBLE), 1) OVER (ORDER BY date) AS prev_close\n",
    "    FROM Close_csv\n",
    ")\n",
    "SELECT date, close_price, \n",
    "       (close_price - prev_close) AS price_change\n",
    "FROM AAPL_Changes\n",
    "WHERE prev_close IS NOT NULL\n",
    "ORDER BY date DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d39d9e8-ba2f-4d4b-8d19-1699fb8e7184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 22: CASE Statement to Classify Stocks Based on Daily Fluctuation\n",
    "SELECT h.date, h.AAPL AS high, l.AAPL AS low,\n",
    "       CASE \n",
    "           WHEN (CAST(h.AAPL AS DOUBLE) - CAST(l.AAPL AS DOUBLE)) > 10 THEN 'High Volatility'\n",
    "           WHEN (CAST(h.AAPL AS DOUBLE) - CAST(l.AAPL AS DOUBLE)) BETWEEN 5 AND 10 THEN 'Medium Volatility'\n",
    "           ELSE 'Low Volatility'\n",
    "       END AS volatility_category\n",
    "FROM High_csv h\n",
    "JOIN Low_csv l ON h.date = l.date\n",
    "ORDER BY h.date DESC;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7451c80b-0708-49ff-bf17-bc639a0987d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 23: Calculate the 7-Day Moving Average for Each Stock’s Closing Price\n",
    "SELECT c.date, c.AAPL AS close_price,\n",
    "       AVG(CAST(c.AAPL AS DOUBLE)) OVER (ORDER BY c.date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_avg_7d\n",
    "FROM Close_csv c\n",
    "ORDER BY c.date DESC;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a4a15c1-ba51-41b2-9ea8-84ffed4798d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 24: Creating a UDF\n",
    "# Import necessary PySpark functions\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Define Python function for categorization\n",
    "def categorize_stock_movement(change):\n",
    "    try:\n",
    "        change = float(change)  # Ensure that the input is treated as a float\n",
    "    except ValueError:\n",
    "        return 'Invalid Data'\n",
    "    \n",
    "    if change > 15:\n",
    "        return 'Significant Increase'\n",
    "    elif change < -15:\n",
    "        return 'Significant Decrease'\n",
    "    else:\n",
    "        return 'Stable'\n",
    "\n",
    "# Convert Python function to Spark UDF\n",
    "categorize_udf = udf(categorize_stock_movement, StringType())\n",
    "\n",
    "# Register the UDF so it can be used in SQL\n",
    "spark.udf.register(\"CategorizeStockMovement\", categorize_stock_movement, StringType())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7af36576-5b0f-4335-b760-02c364a21ded",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 25: Calling a UDF\n",
    "SELECT date, AAPL, CategorizeStockMovement(AAPL) AS Movement_Category\n",
    "FROM Close_csv;\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3591480876550794,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Stock - Data Analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
